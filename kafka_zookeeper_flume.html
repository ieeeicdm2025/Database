<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="Academic Webpage" />
    <meta name="author" content="senli1073" />
    <title id="title"></title>

    <!-- Icon -->
    <link rel="icon" type="image/x-icon" href="static/assets/favicon.ico" />

    <!-- Bootstrap icons-->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css" rel="stylesheet" />

    <!-- Google fonts-->
    <link rel="preconnect" href="https://fonts.gstatic.com" />
    <link href="https://fonts.googleapis.com/css2?family=Newsreader:ital,wght@0,600;1,600&amp;display=swap"
        rel="stylesheet" />
    <link
        href="https://fonts.googleapis.com/css2?family=Mulish:ital,wght@0,300;0,500;0,600;0,700;1,300;1,500;1,600;1,700&amp;display=swap"
        rel="stylesheet" />
    <link href="https://fonts.googleapis.com/css2?family=Kanit:ital,wght@0,400;1,400&amp;display=swap"
        rel="stylesheet" />

    <!-- Core theme CSS (includes Bootstrap)-->
    <link type="text/css" href="static/css/styles.css" rel="stylesheet" />
    <link type="text/css" href="static/css/main.css" rel="stylesheet" />

    <!-- Bootstrap core JS-->
    <script type="text/javascript" src="static/js/bootstrap.bundle.min.js"></script>

    <style>
        pre {
            background-color: #f4f4f4;
            padding: 10px;
            border-radius: 5px;
            border: 1px solid #ddd;
            font-family: monospace;
        }

        code {
            color: #333;
        }
    </style>

    <!-- For Compatability -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Markdown -->
    <script type="text/javascript" src="static/js/marked.min.js"></script>

    <!-- Mathematics -->
    <script>
        // See https://docs.mathjax.org/en/latest/index.html for more details.
        MathJax = {
            tex: {
                packages: {},              // extensions to use
                inlineMath: [              // start/end delimiter pairs for in-line math
                    ['$', '$'],
                    ['\\(', '\\)']
                ],
                displayMath: [             // start/end delimiter pairs for display math
                    ['$$', '$$'],
                    ['\\[', '\\]']
                ],
                processEscapes: false,      // use \$ to produce a literal dollar sign
                processEnvironments: true, // process \begin{xxx}...\end{xxx} outside math mode
                processRefs: true,         // process \ref{...} outside of math mode
                digits: /^(?:[0-9]+(?:\{,\}[0-9]{3})*(?:\.[0-9]*)?|\.[0-9]+)/,    // pattern for recognizing numbers
                tags: 'all',              // or 'ams' or 'all'
                tagSide: 'right',          // side for \tag macros
                tagIndent: '0.8em',        // amount to indent tags
                useLabelIds: true,         // use label name rather than tag for ids
                maxMacros: 10000,          // maximum number of macro substitutions per expression
                maxBuffer: 5 * 1024,       // maximum size for the internal TeX string (5K)
                // baseURL:                   // URL for use with links to tags (when there is a <base> tag in effect)
                // (document.getElementsByTagName('base').length === 0) ? '' : String(document.location).replace(/#.*$/, ''),
                formatError:               // function called when TeX syntax errors occur
                    (jax, err) => jax.formatError(err)
            }
        };
    </script>
    <script type="text/javascript" id="MathJax-script"
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Core JS-->
    <script type="text/javascript" src="static/js/scripts.js"></script>
    <script type="text/javascript" src="static/js/js-yaml.min.js"></script>

</head>

<body id="page-top">
    <!-- Navigation-->
    <nav class="header navbar navbar-expand-lg navbar-light fixed-top shadow-sm" id="mainNav">
        <div class="container px-5">
            <a id="page-top-title" class="navbar-brand fw-bold" href="#page-top"></a>
            <!-- <a href="#page-top"><img src="static/assets/img/CUMT_LOGO.svg" style="width: 11rem;"></a> -->
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive"
                aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                MENU
                <i class="bi-list"></i>
            </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav ms-auto me-4 my-3 my-lg-0">
                    <li class="nav-item">
                        <a class="nav-link me-lg-3" href="index.html" style="font-size: 30px;">首页</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link me-lg-3" href="expriment.html" style="font-size: 30px;">实验指南</a>
                    </li>
                    <!-- <li class="nav-item">
                        <a class="nav-link me-lg-3" href="ppt.html" style="font-size: 30px;"><strong>PPT</strong></a>
                    </li> -->

                </ul>
            </div>
        </div>
    </nav>

    <!-- Top Section -->
    <section class="top-section" style="background-image: url('static/assets/img/background.jpeg');">
        <div class="top-section-content">
            <div class="container px-5">
                <h2 id="top-section-bg-text" class="text-white display-3 lh-1 font-alt"></h2>
            </div>
        </div>
    </section>
    <!-- Top Section -->

    <!-- Photo -->
    <div class="container px-5">
        <div id="avatar">
            <img class="shadow" src="static/assets/img/photo.png">
        </div>
    </div>
    <!-- Photo -->

    <!-- Home -->
    <section class="bg-gradient-primary-to-secondary-light mt5 md5" id="home">
        <div class="container px-5">
            <header>
                <h2 id="home-subtitle"> </h2>
                <!-- <span class="bi bi-list"></span> -->
            </header>
            <div class="main-body" id="home-md"></div>
        </div>
    </section>
    <!-- Home -->



    <!-- Awards -->
    <section class="bg-gradient-primary-to-secondary-light mt5 md5" id="awards">
        <div class="container px-5">
            <header>
                <h2 id="awards-subtitle" style="font-size: 48px;"><i class="bi bi-award-fill"></i> 实验指南(九)：Zookeeper、Kafka和Flume</h2>
            </header>

            <div style="height: 64px;"></div>

            <div class="main-body" id="awards-md">

                <h1 id="flink"><strong>Zookeeper、Kafkak和Flume</strong></h1>
                <div style="height: 32px;"></div>
                <h2 id="1-7"><strong>1、Zookeeper（<a
                    href="https://zookeeper.apache.org/" target="_blank">官网</a>）</strong></h2>
                <p>ZooKeeper 是一个开放源码的分布式协调服务，主要为了解决分布式架构下数据一致性问题，它是集群的管理者，监视着集群中各个节点的状态，根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</p>
                <img src="static/assets/img/kafka_zookeeper/zookeeper_achi.png" alt="zookeeper_achi" style="width: 100%; height: auto;">
                
                <p><strong>（1）数据模型</strong></p>
                <ul>
                    <li>ZooKeeper 采用层次化的目录结构，类似于文件系统，每个数据单元称为 ZNode 。整个 ZooKeeper 存储的数据可以看作是一个树状结构，每个节点可以存储少量数据，并且可以有子节点。</li>
                </ul>
                <p><strong>（2）ZAB 协议（ZooKeeper Atomic Broadcast）</strong></p>
                <ul>
                    <li>ZooKeeper 采用 ZAB 协议 作为其核心一致性算法，确保分布式环境下的数据一致性，并能很好地支持崩溃恢复。</li>
                </ul>
                
                <ul>
                    <li>ZAB 的工作模式</li>
                    <li style="padding-left: 20px; list-style-position: inside;">崩溃恢复模式：当 ZooKeeper 集群启动或 Leader 发生故障时，进入恢复模式，选举新的 Leader 并同步数据。</li>
                    <li style="padding-left: 20px; list-style-position: inside;">广播模式：Leader 选举完成后，所有事务性请求（写操作）都由 Leader 处理，并通过 ZAB 进行复制到 Follower。</li>
                </ul>

                <ul>
                    <li>ZAB 中三个主要的角色</li>
                    <li style="padding-left: 20px; list-style-position: inside;">Leader ：集群中唯一的写请求处理者 ，能够发起投票（投票也是为了进行写请求）。</li>
                    <li style="padding-left: 20px; list-style-position: inside;">Follower：能够接收客户端的请求，如果是读请求则可以自己处理，如果是写请求则要转发给 Leader 。在选举过程中会参与投票，有选举权和被选举权 。</li>
                    <li style="padding-left: 20px; list-style-position: inside;">Observer ：没有选举权和被选举权的 Follower 。</li>
                </ul>
                
                <p><strong>（3）Watcher 机制</strong></p>
                <ul>
                    <li>ZooKeeper 提供了一种 观察者（Watcher）机制，允许客户端监听 ZNode 变化，并在数据或节点发生变更时收到通知。</li>
                    <li>Watcher 的触发条件</li>
                    <li style="padding-left: 20px; list-style-position: inside;">节点数据变化（修改、删除）</li>
                    <li style="padding-left: 20px; list-style-position: inside;">节点子节点列表变化（添加、删除子节点）</li>
                    <li style="padding-left: 20px; list-style-position: inside;">节点创建或删除（适用于监听不存在的节点）</li>
                    
                </ul>
                <p><strong>（4）会话管理</strong></p>
                <p>窗口是流处理中用于分组和聚合事件的机制。Flink 支持多种窗口类型：</p>
                <ul>
                    <li>ZooKeeper 使用 会话（Session） 来管理客户端连接，每个客户端连接到 ZooKeeper 时都会创建一个会话。 客户端会定期向 ZooKeeper 发送心跳，防止会话超时，如果客户端在会话超时前重新连接 ZooKeeper，可以继续使用原会话 ID。如果客户端长时间不与 ZooKeeper 交互（超时），ZooKeeper 认为该客户端已经断开连接，并删除它的临时节点。</li>
                </ul>
                
                <h2 id="2flink"><strong>2、Kafkak（<a
                    href="https://kafka.apache.org/" target="_blank">官网</a>）</strong></h2>
                <p>Kafka 是一个分布式流处理平台，广泛应用于高吞吐量的消息传递和实时数据流处理。它能够处理大量的实时数据流，并且支持分布式、高可用和高可扩展的架构。</p>
                <img src="static/assets/img/kafka_zookeeper/kafka_achi.png" alt="kafka_achi" style="width: 100%; height: auto;">
                
                <p><strong>（1）Producer（生产者）</strong></p>
                <ul>
                    <li>Producer 是消息的生产者，它负责将消息发送到 Kafka 中的指定 Topic。Producer 可以将消息发送到特定的分区，也可以让 Kafka 自动选择分区。Producer 是消息流入 Kafka 系统的源头。</li>
                </ul>
                <p><strong>（2）Consumer（消费者）</strong></p>
                <ul>
                    <li>Consumer 是从 Kafka 中消费消息的客户端。它可以从一个或多个 Topic 中获取消息并进行处理。消费者通常组成一个消费者组（Consumer Group），多个消费者并行处理消息。</li>
                    <li>Consumer Group（消费者组）是 Kafka 中消费者的一个重要概念。一个消费者组中的多个消费者共同消费一个或多个 Topic 中的消息。Kafka 确保每个分区只会被消费者组中的一个消费者消费，这样就可以实现负载均衡。</li>
                </ul>
                <p><strong>（3）Topic（主题）</strong></p>
                <ul>
                    <li>Topic 是 Kafka 中消息的逻辑分类，生产者将消息发布到特定的 Topic，消费者则从指定的 Topic 中消费消息。</li>
                </ul>

                <p><strong>（4）Partition（分区）</strong></p>
                <ul>
                    <li>每个 Kafka Topic 都可以被划分为多个分区。每个分区是 Kafka 中的基本存储单位，消息会被分布到不同的分区中。分区使 Kafka 可以横向扩展，提升吞吐量。</li>
                </ul>

                <p><strong>（5）Broker（代理）</strong></p>
                <ul>
                    <li>Broker 是 Kafka 的核心服务器，负责存储消息并处理客户端的请求。一个 Kafka 集群由多个 Broker 组成，Kafka 集群的规模可以随着业务需求的增加进行横向扩展。</li>
                </ul>

                <p><strong>（6）Offset（偏移量）</strong></p>
                <ul>
                    <li>Kafka 使用偏移量来标识消息在分区中的位置。每个消息在分区内都有一个唯一的偏移量，消费者根据偏移量来消费消息。</li>
                </ul>





                <h2 id="2flink"><strong>3、Flume（<a
                    href="https://flume.apache.org/" target="_blank">官网</a>）</strong></h2>

                <p>Flume是一个分布式的、可靠的、可用的服务，用于高效地收集、聚合和移动大量的日志数据。</p>
                <img src="static/assets/img/hue_flume/flume_achi.png" alt="flume_achi" style="width: 100%; height: auto;">    
                
                <p><strong>（1）一个flume agent（事务）可以分成三部分</strong></p>
                <ul>
                    <li>源（Source）：用于从外部系统（如日志文件、网络流、数据库等）获取数据，并通过将获取到的数据封装成 Event 发送到 Flume 的后续组件。</li>
                    <li>通道（Channel）：用于临时存储从 Source 接收到的事件，直到它们被 Flume 的 Sink 组件处理。</li>
                    <li>接收器（Sink）：用于将事件从 Channel 发送到外部系统（例如 HDFS、Kafka、数据库等）的组件。Sink 会从 Channel 中读取事件，并根据配置将其写入到目标系统中。</li>
                </ul>

                <p><strong>（2）flume 的工作流程</strong></p>
                <ul>
                    <li>Source 从外部系统获取数据并将其转化为 Event。</li>
                    <li>Channel 存储这些 Event，确保数据可靠传输。</li>
                    <li>Sink 从 Channel 中读取 Event，并将其发送到外部存储或分析系统。</li>
                </ul>
  





                <h2 id="3minikubeflink"><strong>4、使用minikube部署Zookeeper与Kafka</strong></h2>
                <p><strong>（1）拉取并向minikube中导入所需的镜像</strong></p>

                <ul>
                    <li>我们先拉取所需镜像</li>
                </ul>
                <pre><code>docker pull bitnami/kafka:latest
docker pull zookeeper:latest
</code></pre>

                <ul>
                    <li>如果出现拉取错误的问题，也可以选择直接导入实验所提供的打包好的镜像</li>
                </ul>
                <pre><code>docker load -i kafka.tar
docker load -i zookeeper.tar
</code></pre>

                <ul>
                    <li>然后向minikube中导入所需的镜像</li>
                </ul>
                
                
                <pre><code>minikube image load bitnami/kafka:latest
minikube image load zookeeper:latest
</code></pre>
                <ul>
                    <li>进入minikube查看是否导入</li>
                </ul>
                <pre><code>minikube ssh
docker images
</code></pre>
<img src="static/assets/img/kafka_zookeeper/kafka_images.png" alt="kafka_image" style="width: 100%; height: auto;">
<br><br>
                <p><strong>（2）使用kafka-deployment.yaml文件部署Kafka与Zookeeper</strong></p>
                <pre><code>kubectl apply -f kafka-deployment.yaml
</code></pre>
                <ul>
                    <li>查看pod状态，确认已正常运行</li>
                </ul>
                <pre><code>kubectl get pods
</code></pre>
<img src="static/assets/img/kafka_zookeeper/kafka_pods.png" alt="kafka_pods" style="width: 100%; height: auto;">
                <br><br>
                <p><strong>（3）测试Kafka与Zookeeper的功能</strong></p>
                <ul>
                    <li>打开三个命令行窗口，并进入wsl中（三个窗口都输入一遍，都进入wsl以备用）</li>
                </ul>
                <pre><code>wsl
</code></pre>
                <ul>
                    <li>第一个窗口中，进入Kafka所在的pod，同样的，下面的kafka-9b4f47bd5-wdmkb需替换为自己创建的pod名称</li>
                </ul>
                <pre><code>kubectl exec -it kafka-9b4f47bd5-wdmkb -- bash
</code></pre>
                <ul>
                    <li>创建一个新的Kafka主题——test-topic</li>
                </ul>
                <pre><code>kafka-topics.sh --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
</code></pre>
                <ul>
                    <li>确认主题是否创建成功</li>
                </ul>
                <pre><code>kafka-topics.sh --list --bootstrap-server localhost:9092
</code></pre>
<img src="static/assets/img/kafka_zookeeper/kafka_theme.png" alt="kafka_theme" style="width: 100%; height: auto;">
                <ul>
                    <li>在这个窗口使用 Kafka 作为生产者发送消息</li>
                </ul>
                <pre><code>kafka-console-producer.sh --topic test-topic --bootstrap-server localhost:9092
</code></pre>
                <ul>
                    <li>输入待发送的消息，再回车即为发送</li>
                </ul>
                <pre><code>Hello Kafka
Hello Zookeeper
</code></pre>
<img src="static/assets/img/kafka_zookeeper/kafka_producer.png" alt="kafka_producer" style="width: 100%; height: auto;">

                <ul>
                    <li>不要关闭第一个窗口，同时打开第二个命令行窗口，进入Kafka所在的pod，同样的，下面的kafka-9b4f47bd5-wdmkb需替换为自己创建的pod名称</li>
                </ul>
                <pre><code>kubectl exec -it kafka-9b4f47bd5-wdmkb -- bash
</code></pre>
                <ul>
                    <li>在这个窗口使用 Kafka 作为消费者接收消息</li>
                </ul>
                <pre><code>kafka-console-consumer.sh --topic test-topic --bootstrap-server localhost:9092 --from-beginning
</code></pre>
<img src="static/assets/img/kafka_zookeeper/kafka_consumer.png" alt="kafka_consumer" style="width: 100%; height: auto;">



                <ul>
                    <li>此时可以打开第一个窗口继续输入消息并回车发送，同时在第二个窗口中也能持续接收到相应的内容，并可以使用 ctrl+c 退出发送/接收的命令行</li>
                </ul>
                <ul>
                    <li>再打开第三个命令行窗口，进入Zookeeper所在的pod，同样的，下面的zookeeper-85fc45c-sqpsp需替换为自己创建的pod名称</li>
                </ul>
                <pre><code>kubectl exec -it zookeeper-85fc45c-sqpsp -- bash
</code></pre>
                <ul>
                    <li>连接到Zookeeper</li>
                </ul>
                <pre><code>zkCli.sh -server localhost:2181
</code></pre>
<img src="static/assets/img/kafka_zookeeper/zookeeper1.png" alt="kafka_zookeeper1" style="width: 100%; height: auto;">


                <ul>
                    <li>往下滑动，能看到 Welcome to Zookeeper 字样</li>
                </ul>
<img src="static/assets/img/kafka_zookeeper/zookeeper2.png" alt="kafka_zookeeper2" style="width: 100%; height: auto;">

                <ul>
                    <li>由于Kafka 会在 Zookeeper 中创建一系列路径来存储主题和分区的信息，因此我们在这里列出所有的主题。这里可以看到我们最初所创建的 test-topic 主题以及用于存储消费偏移量的内部主题__consumer_offsets</li>
                </ul>
                <pre><code>ls /brokers/topics</code></pre>
<img src="static/assets/img/kafka_zookeeper/zookeeper3.png" alt="kafka_zookeeper3" style="width: 100%; height: auto;">

                <br><br>




                <!-- <h2 id="3minikubeflink"><strong>4、kafka-tools的使用（Offset Explorer）</strong></h2>

                <ul>
                    <li>先在命令行配置端口转发</li>
                </ul>
                <pre><code>kubectl port-forward svc/kafka 9092:9092</code></pre>
<img src="static/assets/img/kafka_zookeeper/kafka_port.png" alt="kafka_port" style="width: 100%; height: auto;">

                <ul>
                    <li>打开Offset Explorer.exe执行程序，安装kafka-tools，注意设置下安装位置，其它的都点 next 就好</li>
                </ul>
<img src="static/assets/img/kafka_zookeeper/kafka_install.png" alt="kafka_install" style="width: 100%; height: auto;">

                <ul>
                    <li>按照图示方式配置kafka与zookeeper</li>
                </ul>
<img src="static/assets/img/kafka_zookeeper/kafka_connect.png" alt="kafka_connect" style="width: 100%; height: auto;">

                <ul>
                    <li>刷新topic</li>
                </ul>
<img src="static/assets/img/kafka_zookeeper/kafka_refresh.png" alt="kafka_refresh" style="width: 100%; height: auto;">


                <ul>
                    <li>可以看到我们刚刚所创建的topic</li>
                </ul>
<img src="static/assets/img/kafka_zookeeper/kafka_result.png" alt="kafka_result" style="width: 100%; height: auto;">

<br><br> -->
                <h2 id="1"><strong>5、使用minikube部署flume</strong></h2>
                <p><strong>（1）制作并向minikube中导入所需的镜像</strong></p>
                
                <ul>
                    <li>我们先制作所需镜像</li>
                </ul>
                <pre><code>docker build -f dockerfile_flume -t flume:latest .
</code></pre>
                
                <ul>
                    <li>如果出现拉取错误的问题，也可以选择直接导入实验所提供的打包好的镜像</li>
                </ul>
                <pre><code>docker load -i flume.tar
</code></pre>

                <ul>
                    <li>然后向minikube中导入所需的镜像</li>
                </ul>   
            
                <pre><code>minikube image load flume:latest
</code></pre>
                <ul>
                    <li>进入minikube查看是否导入</li>
                </ul>
                <pre><code>minikube ssh
docker images
</code></pre>
<img src="static/assets/img/hue_flume/flume_load.png" alt="load" style="width: 100%; height: auto;">

                <p><strong>（2）由于这里展示的flume是集成到Hadoop和kafka中的，kafka在之前的实验中已经配置过了，因此需要先使用hadoop-cluster.yaml文件部署Hadoop，部署后查看pod状态验证其是否正常运行</strong></p>
                <pre><code>kubectl apply -f hadoop-cluster.yaml
kubectl get pods
</code></pre>
<img src="static/assets/img/hue_flume/flume_hadoop.png" alt="hadoop" style="width: 100%; height: auto;">


                <ul>
                    <li>由于flume的日志是写在hdfs上的，因此，我们到hdfs上预先为其建立一个文件夹以存放flume日志</li>
                </ul>
                <ul>
                    <li>我们先布置hdfs的端口转发，以在浏览器中访问到hdfs</li>
                </ul>
                <pre><code>kubectl port-forward svc/namenode 9870:9870
</code></pre>
<img src="static/assets/img/hue_flume/flume_port.png" alt="hadoop_port" style="width: 100%; height: auto;">

                <ul>
                    <li>在浏览器中输入如下地址</li>
                </ul>
                <a href="http://localhost:9870/" target="_blank">http://localhost:9870/</a>
<img src="static/assets/img/hue_flume/flume_webui1.png" alt="hadoop_webui1" style="width: 100%; height: auto;">

                <ul>
                    <li>点击这里可以进入文件管理界面</li>
                </ul>
<img src="static/assets/img/hue_flume/flume_webui2.png" alt="hadoop_webui2" style="width: 100%; height: auto;">


                <ul>
                    <li>接着我们回到命令行，进入namenode所在的pod，同样地，这里的namenode-764bfd689f-85pd7需替换为自己的pod名</li>
                </ul>
                <pre><code>kubectl exec -it namenode-764bfd689f-85pd7 -- bash
</code></pre>

                <ul>
                    <li>而后在hdfs上创建文件夹并更改其权限</li>
                </ul>
                <pre><code>hdfs dfs -mkdir -p /flume/data
hdfs dfs -chmod 777 /flume
</code></pre>

<img src="static/assets/img/hue_flume/flume_create.png" alt="flume_create" style="width: 100%; height: auto;">

                <p><strong>（3）使用flume-deployment.yaml文件部署flume，并查看pod状态验证其是否正常运行</strong></p>
                <pre><code>kubectl apply -f flume-deployment.yaml
kubectl get pods
</code></pre>

<img src="static/assets/img/hue_flume/flume_apply.png" alt="flume_apply" style="width: 100%; height: auto;">


                <ul>
                    <li>创建完毕后我们可以进入flume所在的pod，以验证其是否能与hdfs连接，图中可以看到我们刚刚为flume建立的文件夹/flume/data</li>
                </ul>
                <pre><code>hdfs dfs -ls /
</code></pre>

<img src="static/assets/img/hue_flume/flume_test.png" alt="flume_test" style="width: 100%; height: auto;">

                <p><strong>（4）测试flume的功能</strong></p>

                <ul>
                    <li>下图是flume的部署文件中有关flume连接配置的部分</li>
                </ul>


                <ul>
                    <li>可以看到在这里我们定义了两个内存通道（mem-channel-1和mem-channel-2）用于存储数据，相应地也定义了两个接收端：kafka-sink和hdfs-sink，数据将被传输到这两个目标</li>
                </ul>


                <ul>
                    <li>在log-source的相关配置处，我们进一步定义了source的类型为TAILDIR，即从指定目录中持续读取日志文件并获取新的数据，以及我们所要监听的目录，即/var/log/app/下的所有.log文件</li>
                </ul>


                <ul>
                    <li>在Channel的相关配置处，我们定义了两个通道都使用内存通道，且每个通道最多存储10000个事件</li>
                </ul>


                <ul>
                    <li>在kafka-sink的配置处，我们指定了Kafka的地址：kafka:9092，并定义将数据写入的Kafka主题为logs-topic</li>
                </ul>

                <ul>
                    <li>在hdfs-sink的配置处，我们指定了数据写入的HDFS路径：hdfs://namenode:9000/flume/data/%Y-%m-%d/，它根据当前日期创建目录，并定义每个文件的前缀为events-</li>
                </ul>


<img src="static/assets/img/hue_flume/flume_deployment.png" alt="flume_test" style="width: 100%; height: auto;">




                <ul>
                    <li>我们先打开一个新的命令行窗口，并进入kafka所在的pod，同样地，这里的kafka-9b4f47bd5-6z7l7需替换为实际的pod名称</li>
                </ul>
                <pre><code>kubectl exec -it kafka-9b4f47bd5-6z7l7 -- bash
</code></pre>

                <ul>
                    <li>然后创建一个新的topic用来接收日志</li>
                </ul>
                <pre><code>kafka-topics.sh --create --topic logs-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
</code></pre>
<img src="static/assets/img/hue_flume/flume_kafka_topic.png" alt="flume_kafka_wait" style="width: 100%; height: auto;">

                <ul>
                    <li>而后启动kafka消费者，放在这等待flume的消息</li>
                </ul>
                <pre><code>kafka-console-consumer.sh --topic logs-topic --bootstrap-server localhost:9092 --from-beginning
</code></pre>

<img src="static/assets/img/hue_flume/flume_kafka_wait.png" alt="flume_kafka_wait" style="width: 100%; height: auto;">

                <ul>
                    <li>由于在flume的部署文件中，我们已经将/var/log/app/设置为了它的监听目录，因此我们回到刚刚部署完flume的命令行，进入flume所在的pod中，写入一个文件到它所监听的这个目录下，同样地，这里的flume-agent-ccc7854f5-97hbm需替换为实际的pod名</li>
                </ul>
                <pre><code>kubectl exec -it flume-agent-ccc7854f5-97hbm -- bash
for i in {1..5}; do
   echo "Text Test $i $(date '+%Y-%m-%d %H:%M:%S')" >> /var/log/app/text_test.log
done
</code></pre>

<img src="static/assets/img/hue_flume/flume_write.png" alt="flume_write" style="width: 100%; height: auto;">

                <ul>
                    <li>接着我们切换到刚刚kafka消费者所在的窗口，可以看到我们刚刚写入的消息</li>
                </ul>
<img src="static/assets/img/hue_flume/flume_kafka_write.png" alt="flume_write" style="width: 100%; height: auto;">
                


                <ul>
                    <li>而后我们来到hdfs上存放flume数据的对应目录下，可以看到它已经自动生成了以日期命名的子文件夹</li>
                </ul>

<img src="static/assets/img/hue_flume/flume_date.png" alt="flume_date" style="width: 100%; height: auto;">

                <ul>
                    <li>我们进入这个文件夹，可以看到flume写入hdfs的.tmp临时文件</li>
                </ul>

<img src="static/assets/img/hue_flume/flume_tmp.png" alt="flume_tmp" style="width: 100%; height: auto;">

                <ul>
                    <li>这里我们需要静待一会，等待它写入完毕，此时.tmp后缀会消失</li>
                </ul>

<img src="static/assets/img/hue_flume/flume_events.png" alt="flume_events" style="width: 100%; height: auto;">


                <ul>
                    <li>而后我们回到命令行中的flume所在的pod中，从hdfs上查看flume写入的日志文件，这里的/2025-02-14/events-.1739543662388需要替换为实际的文件</li>
                </ul>
                <pre><code>hdfs dfs -cat /flume/data/2025-02-14/events-.1739543662388
</code></pre>
<img src="static/assets/img/hue_flume/flume_cat1.png" alt="flume_get" style="width: 100%; height: auto;">


                <ul>
                    <li>接下来我们可以用之前我们手动写入flume所监听的文件夹的文件与flume监听后写入hdfs的文件做对比，是完全一致的</li>
                </ul>
                <pre><code>cat /var/log/app/text_test.log
</code></pre>

<img src="static/assets/img/hue_flume/flume_cat2.png" alt="flume_cat2" style="width: 100%; height: auto;">





            </div>

        </div>
    </section>
    <!-- Awards -->


    <!-- Footer-->
    <footer class="bg-bottom text-center py-5">
        <div class="container px-5">

        </div>
    </footer>

</body>

</html>