<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="Academic Webpage" />
    <meta name="author" content="senli1073" />
    <title id="title"></title>

    <!-- Icon -->
    <link rel="icon" type="image/x-icon" href="static/assets/favicon.ico" />

    <!-- Bootstrap icons-->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css" rel="stylesheet" />

    <!-- Google fonts-->
    <link rel="preconnect" href="https://fonts.gstatic.com" />
    <link href="https://fonts.googleapis.com/css2?family=Newsreader:ital,wght@0,600;1,600&amp;display=swap"
        rel="stylesheet" />
    <link
        href="https://fonts.googleapis.com/css2?family=Mulish:ital,wght@0,300;0,500;0,600;0,700;1,300;1,500;1,600;1,700&amp;display=swap"
        rel="stylesheet" />
    <link href="https://fonts.googleapis.com/css2?family=Kanit:ital,wght@0,400;1,400&amp;display=swap"
        rel="stylesheet" />

    <!-- Core theme CSS (includes Bootstrap)-->
    <link type="text/css" href="static/css/styles.css" rel="stylesheet" />
    <link type="text/css" href="static/css/main.css" rel="stylesheet" />

    <!-- Bootstrap core JS-->
    <script type="text/javascript" src="static/js/bootstrap.bundle.min.js"></script>

    <style>
        pre {
            background-color: #f4f4f4;
            padding: 10px;
            border-radius: 5px;
            border: 1px solid #ddd;
            font-family: monospace;
        }

        code {
            color: #333;
        }
    </style>

    <!-- For Compatability -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Markdown -->
    <script type="text/javascript" src="static/js/marked.min.js"></script>

    <!-- Mathematics -->
    <script>
        // See https://docs.mathjax.org/en/latest/index.html for more details.
        MathJax = {
            tex: {
                packages: {},              // extensions to use
                inlineMath: [              // start/end delimiter pairs for in-line math
                    ['$', '$'],
                    ['\\(', '\\)']
                ],
                displayMath: [             // start/end delimiter pairs for display math
                    ['$$', '$$'],
                    ['\\[', '\\]']
                ],
                processEscapes: false,      // use \$ to produce a literal dollar sign
                processEnvironments: true, // process \begin{xxx}...\end{xxx} outside math mode
                processRefs: true,         // process \ref{...} outside of math mode
                digits: /^(?:[0-9]+(?:\{,\}[0-9]{3})*(?:\.[0-9]*)?|\.[0-9]+)/,    // pattern for recognizing numbers
                tags: 'all',              // or 'ams' or 'all'
                tagSide: 'right',          // side for \tag macros
                tagIndent: '0.8em',        // amount to indent tags
                useLabelIds: true,         // use label name rather than tag for ids
                maxMacros: 10000,          // maximum number of macro substitutions per expression
                maxBuffer: 5 * 1024,       // maximum size for the internal TeX string (5K)
                // baseURL:                   // URL for use with links to tags (when there is a <base> tag in effect)
                // (document.getElementsByTagName('base').length === 0) ? '' : String(document.location).replace(/#.*$/, ''),
                formatError:               // function called when TeX syntax errors occur
                    (jax, err) => jax.formatError(err)
            }
        };
    </script>
    <script type="text/javascript" id="MathJax-script"
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Core JS-->
    <script type="text/javascript" src="static/js/scripts.js"></script>
    <script type="text/javascript" src="static/js/js-yaml.min.js"></script>

</head>

<body id="page-top">
    <!-- Navigation-->
    <nav class="header navbar navbar-expand-lg navbar-light fixed-top shadow-sm" id="mainNav">
        <div class="container px-5">
            <a id="page-top-title" class="navbar-brand fw-bold" href="#page-top"></a>
            <!-- <a href="#page-top"><img src="static/assets/img/CUMT_LOGO.svg" style="width: 11rem;"></a> -->
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive"
                aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                MENU
                <i class="bi-list"></i>
            </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav ms-auto me-4 my-3 my-lg-0">
                    <li class="nav-item">
                        <a class="nav-link me-lg-3" href="index.html" style="font-size: 30px;">首页</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link me-lg-3" href="expriment.html" style="font-size: 30px;">实验指南</a>
                    </li>
                    <!-- <li class="nav-item">
                        <a class="nav-link me-lg-3" href="ppt.html" style="font-size: 30px;"><strong>PPT</strong></a>
                    </li> -->

                </ul>
            </div>
        </div>
    </nav>

    <!-- Top Section -->
    <section class="top-section" style="background-image: url('static/assets/img/background.jpeg');">
        <div class="top-section-content">
            <div class="container px-5">
                <h2 id="top-section-bg-text" class="text-white display-3 lh-1 font-alt"></h2>
            </div>
        </div>
    </section>
    <!-- Top Section -->

    <!-- Photo -->
    <div class="container px-5">
        <div id="avatar">
            <img class="shadow" src="static/assets/img/photo.png">
        </div>
    </div>
    <!-- Photo -->

    <!-- Home -->
    <section class="bg-gradient-primary-to-secondary-light mt5 md5" id="home">
        <div class="container px-5">
            <header>
                <h2 id="home-subtitle"> </h2>
                <!-- <span class="bi bi-list"></span> -->
            </header>
            <div class="main-body" id="home-md"></div>
        </div>
    </section>
    <!-- Home -->



    <!-- Awards -->
    <section class="bg-gradient-primary-to-secondary-light mt5 md5" id="awards">
        <div class="container px-5">
            <header>
                <h2 id="awards-subtitle" style="font-size: 48px;"><i class="bi bi-award-fill"></i> 实验指南(二)：Hadoop
                </h2>
            </header>

            <br>
            <li style="font-size: 20px;">本实验所用到的文件在山大云盘的存放位置为：.\实验材料\实验文件\exp2-hadoop，所用到的文件如下：config.xml、data.txt、dockerfile_hadoop、input.txt、k-means-1.0-SNAPSHOT.jar、spark-hadoop-numpy.tar</li>

            <div style="height: 64px;"></div>

            <div class="main-body" id="awards-md">


                <h1 id="hadoop"><strong>Hadoop（<a
                    href="https://hadoop.apache.org/" target="_blank">官网</a>）</strong></h1>
                <div style="height: 32px;"></div>
                <h2 id="1-2"><strong>1、简介</strong></h2>
                <p>Hadoop 是一个开源的分布式计算框架，用于处理大量的数据集。它是由 Apache 软件基金会维护，旨在通过简单的编程模型将大量数据分布到不同的计算机节点上，从而实现数据的分布式存储和计算。</p>
                <img src="static/assets/img/hadoop_spark/hadoop_achi1.png" alt="hadoop_achi1" style="width: 100%; height: auto;"/>
                <br><br>
                <h2 id="2hadoop"><strong>2、Hadoop的核心概念</strong></h2>
                <p><strong>（1）HDFS（Hadoop Distributed File System）</strong></p>
                <ul>
                    <li>HDFS 是 Hadoop 的分布式存储系统，用于存储大数据。</li>
                    <li>块：HDFS将文件切分成多个块（block），并将这些块分布到集群中的不同节点上。每个块的默认大小通常是 128MB 或 256MB，可以通过配置文件调整</li>
                    <li>NameNode（主节点）：是 HDFS 的核心组件之一，负责管理文件系统的元数据（metadata）。元数据包括文件和块之间的映射关系、每个块的副本位置、目录结构等信息。</li>
                    <li>DataNode（数据节点）：DataNode 是 HDFS 中的数据存储节点，负责存储实际的文件数据块。每个 DataNode 存储文件的多个块，并周期性地向 NameNode
                        报告存储的块的健康状态。</li>
                    <li>副本（Replication）：为了保证数据的高可用性，HDFS 会在集群中的多个节点上存储同一个数据块的副本。默认情况下，每个块会存储 3 个副本（可以通过配置修改）。</li>
                </ul>
                <p><strong>（2）MapReduce</strong></p>
                <ul>
                    <li>MapReduce 是 Hadoop 的核心计算模型，用于处理大规模数据集。它分为两个阶段：</li>
                    <li>Map 阶段：输入数据被拆分成多个片段，并并行地处理每个数据片段，生成中间结果。</li>
                    <li>Reduce 阶段：将来自 Map 阶段的结果进行合并，得到最终输出</li>
                </ul>
                <p><strong>（3）YARN（Yet Another Resource Negotiator）</strong></p>
                <ul>
                    <li>YARN 是 Hadoop 的资源管理层，负责管理集群中的资源（CPU、内存等）并调度任务执行。它提供了一个统一的资源管理框架，支持 MapReduce、Spark
                        等多种计算框架在同一集群上运行。</li>
                    <li>资源管理器（ResourceManager, RM）：负责全局的资源管理和任务调度</li>
                    <li>节点管理器（NodeManager, NM）：负责管理每个集群节点上的资源和任务执行。</li>
                    <li>应用程序管理器（ApplicationMaster, AM）：ApplicationMaster 是每个应用程序（作业）对应的一个实例，负责管理应用程序的生命周期</li>
                    <li>容器（Container）：是 YARN 中资源分配的基本单位，它封装了一个作业的资源需求（如 CPU、内存等）以及运行作业的环境（如环境变量、JAR 文件等）</li>
                </ul>
                <img src="static/assets/img/hadoop_spark/hadoop_achi2.png" alt="hadoop_achi2" style="width: 100%; height: auto;"/>
                <br><br>
                <h2 id="3minikubehadoop"><strong>3、使用minikube部署Hadoop</strong></h2>
                <p><strong>（1）制作并向minikube中导入所需的镜像</strong></p>

                <ul>
                    <li>我们可以使用dockerfile来制作所需镜像</li>
                </ul>
                <pre><code>docker build -f dockerfile_hadoop -t spark-hadoop-numpy:latest .
</code></pre>
                <ul>
                    <li>如果出现拉取错误的问题，也可以选择直接导入实验所提供的打包好的镜像</li>
                </ul>
                <pre><code>docker load -i spark-hadoop-numpy.tar
</code></pre>
                
                <ul>
                    <li>然后向minikube中导入所需的镜像</li>
                </ul>
                <pre><code>minikube image load spark-hadoop-numpy:latest</code></pre>
                <ul>
                    <li>进入minikube查看是否导入</li>
                </ul>
                <pre><code>minikube ssh
docker images</code></pre>
                <img src="static/assets/img/hadoop_spark/hadoop_image.png" alt="hadoop_image" style="width: 100%; height: auto;"/>
                <br><br>
                <p><strong>（2）使用hadoop-cluster.yaml文件部署Hadoop，并查看pod状态验证其是否正常运行</strong></p>
                <pre><code>kubectl apply -f hadoop-cluster.yaml
kubectl get pods</code></pre>
                <img src="static/assets/img/hadoop_spark/hadoop_run.png" alt="hadoop_run" style="width: 100%; height: auto;"/>
                <br><br>

                <p><strong>（3）HDFS的使用</strong></p>
                <ul>
                    <li>查看自己创建hadoop集群的pod名称，进入任意一个pod，这里进入namenode，同样，这里的 namenode-764bfd689f-zkknj 需替换为自己创建时自动生成的namenode名称 </li>
                </ul>
                <pre><code>kubectl get pods
kubectl exec -it namenode-764bfd689f-zkknj -- bash</code></pre>

                <img src="static/assets/img/hadoop_spark/hdfs1.png" alt="hdfs1" style="width: 100%; height: auto;"/>

                <ul>
                    <li>列出hdfs根目录下的文件目录，此时根目录下没有东西 </li>
                </ul>
                <pre><code>hdfs dfs -ls /</code></pre>

                <ul>
                    <li>在根目录下创建文件夹newland</li>
                </ul>
                <pre><code>hdfs dfs -mkdir /newland</code></pre>
                
                <ul>
                    <li>再次查看根目录下的文件目录，发现有了newland</li>
                </ul>
                <pre><code>hdfs dfs -ls /</code></pre>

                <img src="static/assets/img/hadoop_spark/hdfs2.png" alt="hdfs2" style="width: 100%; height: auto;"/>

                <ul>
                    <li>在本地创建一个test.txt文件</li>
                </ul>
                <pre><code>echo "hello hdfs" > test.txt</code></pre>

                <ul>
                    <li>将这个test.txt文件上传到/newland下</li>
                </ul>
                <pre><code>hdfs dfs -put test.txt /newland</code></pre>

                <ul>
                    <li>查看newland下的文件目录，发现有了test.txt文件</li>
                </ul>
                <pre><code>hdfs dfs -ls /newland</code></pre>

                <ul>
                    <li>查看文件内容，即为hello hdfs</li>
                </ul>
                <pre><code>hdfs dfs -cat /newland/test.txt</code></pre>

                <img src="static/assets/img/hadoop_spark/hdfs3.png" alt="hdfs3" style="width: 100%; height: auto;"/>

                <ul>
                    <li>下载hdfs上的文件test.txt到本地，并重命名为test_downland.txt</li>
                </ul>
                <pre><code>hdfs dfs -get /newland/test.txt /opt/spark/work-dir/test_downland.txt</code></pre>
                
                <ul>
                    <li>查看本地目录，发现刚刚所下载的test_downland.txt文件</li>
                </ul>
                <pre><code>ls
cat test_downland.txt</code></pre>

                <img src="static/assets/img/hadoop_spark/hdfs4.png" alt="hdfs4" style="width: 100%; height: auto;"/>

                <ul>
                    <li>最后删除hdfs上的文件夹newland</li>
                </ul>
                <pre><code>hdfs dfs -rm -r /newland</code></pre>

                <ul>
                    <li>再次查看根目录，发现已经没有文件目录了</li>
                </ul>
                <pre><code>hdfs dfs -ls /</code></pre>

                <img src="static/assets/img/hadoop_spark/hdfs5.png" alt="hdfs5" style="width: 100%; height: auto;"/>

                <ul>
                    <li>而后我们退出该容器，回到命令行中</li>
                </ul>
                <pre><code>exit</code></pre>

                <p><strong>（4）设置端口转发以访问Hadoop的webui</strong></p>
                <ul>
                    <li>设置转发以查看resourcemanager的webui：</li>
                </ul>
                <pre><code>kubectl port-forward svc/resourcemanager 8088:8088
</code></pre>
                <ul>
                    <li>使用kubectl的本地端口转发功能来查看namenode的webui。这个转发命令行界面需要一直保持转发状态，停止转发后就无法访问webui了：</li>
                </ul>
                <pre><code>kubectl port-forward svc/namenode 9870:9870
</code></pre>
                <ul>
                    <li>通过下面的url在浏览器访问：</li>
                </ul>
                <p><a href="http://localhost:8088/" target="_blank">http://localhost:8088/</a></p>
                <p><a href="http://localhost:9870/" target="_blank">http://localhost:9870/</a></p>
                <img src="static/assets/img/hadoop_spark/hadoop_webui1.png" alt="hadoop_webui1" style="width: 100%; height: auto;"/>
                <br><br>
                <img src="static/assets/img/hadoop_spark/hadoop_webui2.png" alt="hadoop_webui2" style="width: 100%; height: auto;"/>
                <br><br>
                <p><strong>（5）运行Hadoop的示例程序wordcount</strong></p>
                <ul>
                    <li>wordcount 示例程序是一个经典的示例，通常用于展示如何使用 Hadoop 进行分布式计算，它通过 MapReduce 模型统计输入文件中每个单词出现的次数。</li>
                    <li>Mapper：负责读取输入数据，将数据转换为键值对。</li>
                    <li>Reducer：负责将相同键的值进行汇总，,统计单词的出现次数。</li>
                    <li>进入namenode的命令行bash，下面的namenode-78587cfc8f-clmkd需要替换为自己的pod名称，可以通过kubectl get pods来查看name的pod名称
                    </li>
                </ul>
                <pre><code>kubectl exec -it namenode-78587cfc8f-clmkd -- bash
</code></pre>
                <ul>
                    <li>创建input.txt文件，作为wordcount程序的输入</li>
                </ul>
                <pre><code>echo -e "Hello Hadoop\nHello Kubernetes" &gt; input.txt
</code></pre>
                <ul>
                    <li>在hdfs上创建目录/input</li>
                </ul>
                <pre><code>hdfs dfs -mkdir -p /input
</code></pre>
                <ul>
                    <li>上传input.txt文件到HDFS</li>
                </ul>
                <pre><code>hdfs dfs -put input.txt /input/
</code></pre>
                <ul>
                    <li>运行wordcount程序</li>
                </ul>
                <pre><code>hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar wordcount /input/input.txt /output
</code></pre>
<img src="static/assets/img/hadoop_spark/hadoop_wc.png" alt="hadoop_wc" style="width: 100%; height: auto;"/>
<br><br>
                <p><strong>（6）运行k-means算法的mapreduce版本</strong></p>
                <ul>
                    <li>将所需的文件与jar包传入namenode，下面命令中的namenode-78587cfc8f-sl48f请替换为自己的namenode所在的pod名称</li>
                    <li>传入需要处理的数据文件data.txt、应用程序的jar包k-means-1.0-SNAPSHOT.jar、环境配置文件config.xml</li>
                </ul>
                <pre><code>kubectl cp data.txt namenode-78587cfc8f-sl48f:/opt/hadoop/
kubectl cp k-means-1.0-SNAPSHOT.jar namenode-78587cfc8f-sl48f:/opt/hadoop/
kubectl cp config.xml namenode-78587cfc8f-sl48f:/opt/hadoop/
</code></pre>
                <ul>
                    <li>进入namenode的命令行bash，同样的，下面命令中的namenode-78587cfc8f-sl48f请替换为自己的namenode所在的pod名称</li>
                </ul>
                <pre><code>kubectl exec -it namenode-78587cfc8f-sl48f -- bash
</code></pre>
                <ul>
                    <li>进入传入文件所在的文件夹（<strong>这一步不要忘记，不然找不到文件</strong>）</li>
                </ul>
                <pre><code>cd /opt/hadoop/
</code></pre>
                <ul>
                    <li>上传所需文件到HDFS</li>
                </ul>
                <pre><code>hadoop fs -put k-means-1.0-SNAPSHOT.jar /input
hadoop fs -put config.xml /input
hadoop fs -put data.txt /input
</code></pre>
                <ul>
                    <li>运行程序</li>
                </ul>
                <pre><code>hadoop jar /opt/hadoop/k-means-1.0-SNAPSHOT.jar it.unipi.hadoop.KMeans /input/data.txt /output
</code></pre>
                <p><strong>注意：HDFS上不能有/output路径存在，如果有的话，使用下面的命令删去</strong></p>
                <pre><code>hadoop fs -rm -r /output
</code></pre>
<img src="static/assets/img/hadoop_spark/hadoop_kmeans1.png" alt="hadoop_kmeans1" style="width: 100%; height: auto;"/>
<br><br>
<img src="static/assets/img/hadoop_spark/hadoop_kmeans2.png" alt="hadoop_kmeans2" style="width: 100%; height: auto;"/>
<br><br>
<img src="static/assets/img/hadoop_spark/hadoop_kmeans3.png" alt="hadoop_kmeans3" style="width: 100%; height: auto;"/>
                <ul>
                    <li>从HDFS上下载并查看结果文件</li>
                </ul>
                <pre><code>hadoop fs -get /user/Hadoop/output/centroids.txt
cat centroids.txt
</code></pre>
<img src="static/assets/img/hadoop_spark/hadoop_kmeans4.png" alt="hadoop_kmeans4" style="width: 100%; height: auto;"/>
<br><br>
                <p>注意，每次k-means算法的结果不一定一样，迭代次数也未必相同，能正常运行即可</p>
                <div style="height: 32px;"></div>
                

            </div>

        </div>
    </section>
    <!-- Awards -->


    <!-- Footer-->
    <footer class="bg-bottom text-center py-5">
        <div class="container px-5">
            
        </div>
    </footer>

</body>

</html>